0. Can you come up out 3 sceneraies which use AI methods?
Ans: Unmanned Vehicle，Face Recognition，alpha go.

1. How do we use Github; Why do we use Jupyter and Pycharm;
Ans: We use Pycharm to code. Jupyter Notebooks are a powerful way to write and iterate on your Python code for data analysis.
We use Git to work with other people and it becomes easier to collaborate on projects.

2. What's the Probability Model?
Ans: A probability model is a mathematical representation of a random phenomenon. It is defined by its sample space, events within the sample space, and probabilities associated with each event.

3. Can you came up with some sceneraies at which we could use Probability Model?
Ans:Weather forecast,Stock Forecast

4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?
Ans:

5. What's the Language Model;
Ans: A statistical language model is a probability distribution over sequences of words. Given such a sequence, say of length m, it assigns a probability to the whole sequence. The language model provides context to distinguish between words and phrases that sound similar.
𝑙𝑎𝑛𝑔𝑢𝑎𝑔𝑒_𝑚𝑜𝑑𝑒𝑙(𝑆𝑡𝑟𝑖𝑛𝑔)=𝑃𝑟𝑜𝑏𝑎𝑏𝑖𝑙𝑖𝑡𝑦(𝑆𝑡𝑟𝑖𝑛𝑔)∈(0,1)

6. Can you came up with some sceneraies at which we could use Language Model?
Ans:Input Method, Taobao Customer Service and Translation Software

7. What's the 1-gram language model;
Ans:An 1-gram is a sequence of 1 words
𝑃𝑟𝑜(𝑤1𝑤2𝑤3𝑤4)=𝑃𝑟(𝑤1|𝑤2𝑤3𝑤4)∗𝑃(𝑤2|𝑤3𝑤4)∗𝑃𝑟(𝑤3|𝑤4)∗𝑃𝑟(𝑤4)

8. What's the disadvantages and advantages of 1-gram language model;
Ans: Unigram language models are often smoothed to avoid instances where P(term) = 0. A common approach is to generate a maximum-likelihood model for the entire collection and linearly interpolate the collection model with a maximum-likelihood model for each document to smooth the model.

9. What't the 2-gram models;
Ans:The bigram model approximates the probability of a word given all the previous words by using only the conditional probability of the preceding word. 
𝑃𝑟𝑜(𝑤1𝑤2𝑤3𝑤4)∼𝑃𝑟(𝑤1|𝑤2)∗𝑃(𝑤2|𝑤3)∗𝑃𝑟(𝑤3|𝑤4)∗𝑃𝑟(𝑤4)